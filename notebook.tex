
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{data\_science\_lesson}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Data Science Lesson - NAI Chieu
Long}\label{data-science-lesson---nai-chieu-long}

    Data scientists spend at least 80\% of the time cleaning the data before
using them to create models to aid in analysis, or to create machine
learning models. Data science practitioners commonly use the following
terminologies:

\begin{longtable}[c]{@{}ll@{}}
\toprule
Layman term & Data science jargon\tabularnewline
\midrule
\endhead
Column & Feature\tabularnewline
Row & Sample\tabularnewline
Header & Attribute\tabularnewline
Table & Matrix (Data frame is commonly used among R and
pandas)\tabularnewline
\bottomrule
\end{longtable}

    Some reference books:

\begin{itemize}
\tightlist
\item
  Python for Data Analysis, 2nd Edition
\item
  Read-world Machine Learning
\item
  Hands-On Machine Learning with scikit-learn \& Tensorflow
\item
  Grokking Deep Learning (not yet published, still in beta)
\item
  Deep Reinforcement Learning Hands On
\end{itemize}

    \subsection{Lesson 1 - Data Loading}\label{lesson-1---data-loading}

    \subsubsection{python reload function}\label{python-reload-function}

One important point in doing data science is that the analysis must be
reproducible; short of writing a very detailed step-by-step instructions
on how to reproduce the result, writing code is the best way (running
the same code again almost always reproduce the same result). Therefore,
I encourage you to write your code in scripts, load the code in the
interpreter, load the data, paly with the result, turn the code, reload
the code, so on and so forth. If you follow these steps, burn the
following statement in your brain:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}137}]:} \PY{k+kn}{from} \PY{n+nn}{importlib} \PY{k}{import} \PY{n}{reload}
          \PY{c+c1}{\PYZsh{} import YOUR\PYZus{}SCRIPT}
          \PY{c+c1}{\PYZsh{} df = YOUR\PYZus{}SCRIPT.load\PYZus{}data()}
          \PY{c+c1}{\PYZsh{} play/examine your data}
          \PY{c+c1}{\PYZsh{} tune your code to incorporate insights}
          \PY{c+c1}{\PYZsh{} reload(YOUR\PYZus{}SCRIPT)}
          \PY{c+c1}{\PYZsh{} df = YOUR\PYZus{}SCRIPT.load\PYZus{}data()}
\end{Verbatim}


    \subsubsection{pandas display options}\label{pandas-display-options}

The following are display settings that you can set to adjust how you
want pandas to dispay the data on-screen, this settings do not affect
the actual data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}138}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}                         
          \PY{c+c1}{\PYZsh{} display at most 10 rows of data}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{10}                      
          \PY{c+c1}{\PYZsh{} display at most 10 columns of data}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{width} \PY{o}{=} \PY{l+m+mi}{30}                            
          \PY{c+c1}{\PYZsh{} use up to 100 columns in the terminal/interpreter}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{k}{lambda} \PY{n}{n} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{n}   
          \PY{c+c1}{\PYZsh{} all numeric values will always display up to 2 decimal places}
\end{Verbatim}


    \subsubsection{pandas read\_csv
function}\label{pandas-readux5fcsv-function}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}139}]:} \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} the function to load csv files}
              \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}                                    
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tomslee\PYZus{}airbnb\PYZus{}singapore\PYZus{}0116\PYZus{}2015\PYZhy{}06\PYZhy{}28.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{c+c1}{\PYZsh{} the filename}
                  \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}                                 \PY{c+c1}{\PYZsh{} indicate delimiter }
                  \PY{n}{na\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                               
                  \PY{c+c1}{\PYZsh{} tell pandas to treat the string \PYZsq{}?\PYZsq{} as NA value }
              \PY{k}{return} \PY{n}{df}
\end{Verbatim}


    \subsubsection{running script}\label{running-script}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}140}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}                         
          \PY{c+c1}{\PYZsh{} display at most 10 rows of data}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{10}                      
          \PY{c+c1}{\PYZsh{} display at most 10 columns of data}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{width} \PY{o}{=} \PY{l+m+mi}{30}                            
          \PY{c+c1}{\PYZsh{} use up to 100 columns in the terminal/interpreter}
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{k}{lambda} \PY{n}{n} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{n}   
          \PY{c+c1}{\PYZsh{} all numeric values will always display up to 2 decimal places}
          
          \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} the function to load csv files}
              \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}                                    
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tomslee\PYZus{}airbnb\PYZus{}singapore\PYZus{}0116\PYZus{}2015\PYZhy{}06\PYZhy{}28.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  \PY{c+c1}{\PYZsh{} the filename}
                  \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}                                 \PY{c+c1}{\PYZsh{} indicate delimiter }
                  \PY{n}{na\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                               
                  \PY{c+c1}{\PYZsh{} tell pandas to treat the string \PYZsq{}?\PYZsq{} as NA value }
          
              \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bedrooms}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{host\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reviews}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{overall\PYZus{}satisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accommodates}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{borough}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{minstay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}modified}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}              \PY{c+c1}{\PYZsh{} drop unnecessary columns}
              \PY{k}{return} \PY{n}{df}
          
          \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}141}]:} \PY{n}{df}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}141}]:}             room\_type  \textbackslash{}
          0        Private room   
          1     Entire home/apt   
          2        Private room   
          3        Private room   
          4     Entire home/apt   
          {\ldots}               {\ldots}   
          2810     Private room   
          2811     Private room   
          2812     Private room   
          2813  Entire home/apt   
          2814     Private room   
          
               neighborhood   price  \textbackslash{}
          0            TS20   71.00   
          1            TS28 1015.00   
          2            MK13   63.00   
          3            TS21  235.00   
          4            MK25  235.00   
          {\ldots}           {\ldots}     {\ldots}   
          2810         MK13   56.00   
          2811         MK06   72.00   
          2812         MK11   46.00   
          2813         TS30  233.00   
          2814         TS24   92.00   
          
                latitude  longitude  
          0         1.30     103.84  
          1         1.32     103.84  
          2         1.44     103.80  
          3         1.30     103.84  
          4         1.31     103.90  
          {\ldots}        {\ldots}        {\ldots}  
          2810      1.43     103.78  
          2811      1.34     103.71  
          2812      1.40     103.75  
          2813      1.28     103.86  
          2814      1.31     103.83  
          
          [2815 rows x 5 columns]
\end{Verbatim}
            
    \subsection{Lesson 2 - Examine Data -
Statistics}\label{lesson-2---examine-data---statistics}

    \subsubsection{basic statistical
summary}\label{basic-statistical-summary}

\begin{itemize}
\tightlist
\item
  df.describe - show the statistical summary for all numeric
  columns/features
\item
  df.min - computes the minimum value for each numeric feature
\item
  df.max - ... for maximum
\item
  df.sum - ...
\item
  df.mean - ...
\item
  df.count - ...
\item
  df.std - standard deviation
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}142}]:} \PY{n}{df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{count}\PY{p}{(}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{p}{)}
          
          \PY{n}{df}\PY{o}{.}\PY{n}{aggregate}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{aggregate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{df}\PY{o}{.}\PY{n}{aggregate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}142}]:}            room\_type  \textbackslash{}
          min  Entire home/apt   
          max      Shared room   
          
              neighborhood   price  \textbackslash{}
          min         MK01   14.00   
          max         TS30 5265.00   
          
               latitude  longitude  
          min      1.25     103.69  
          max      1.46     103.98  
\end{Verbatim}
            
    \subsubsection{pandas aggregate and groupby
function}\label{pandas-aggregate-and-groupby-function}

\begin{itemize}
\tightlist
\item
  df.aggregate - the power of .aggregate is shown in the customization
  you can make in aggregating the data, pass in a dictionary where the
  key is the feature name and the value is the statistical functions.
\item
  df.groupby - computes totals(sum) of all numeric feature by columns
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}143}]:} \PY{n}{df}\PY{o}{.}\PY{n}{agg}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}143}]:}       price
          min   14.00
          max 5265.00
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}144}]:} \PY{n}{df}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}144}]:}                                 price  \textbackslash{}
          neighborhood room\_type                  
          MK01         Entire home/apt 16556.00   
                       Private room     7538.00   
                       Shared room       354.00   
          MK02         Entire home/apt  2704.00   
                       Private room     2162.00   
          {\ldots}                               {\ldots}   
          TS28         Private room     1484.00   
          TS29         Entire home/apt  3007.00   
                       Private room      704.00   
          TS30         Entire home/apt 20672.00   
                       Private room     2994.00   
          
                                        latitude  \textbackslash{}
          neighborhood room\_type                   
          MK01         Entire home/apt     92.24   
                       Private room        74.35   
                       Shared room         11.54   
          MK02         Entire home/apt     10.50   
                       Private room        38.10   
          {\ldots}                                {\ldots}   
          TS28         Private room        23.68   
          TS29         Entire home/apt     19.85   
                       Private room        14.55   
          TS30         Entire home/apt     84.52   
                       Private room        28.17   
          
                                        longitude  
          neighborhood room\_type                   
          MK01         Entire home/apt    7475.39  
                       Private room       6021.53  
                       Shared room         934.49  
          MK02         Entire home/apt     830.45  
                       Private room       3010.37  
          {\ldots}                                 {\ldots}  
          TS28         Private room       1869.15  
          TS29         Entire home/apt    1557.69  
                       Private room       1142.32  
          TS30         Entire home/apt    6854.25  
                       Private room       2284.75  
          
          [150 rows x 3 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}145}]:} \PY{n}{df}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{aggregate}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}} \PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}145}]:}                               price  \textbackslash{}
                                          min   
          neighborhood room\_type                
          MK01         Entire home/apt  89.00   
                       Private room     42.00   
                       Shared room      26.00   
          MK02         Entire home/apt 132.00   
                       Private room     24.00   
          {\ldots}                             {\ldots}   
          TS28         Private room     38.00   
          TS29         Entire home/apt  75.00   
                       Private room     39.00   
          TS30         Entire home/apt 159.00   
                       Private room     61.00   
          
                                                
                                           max  
          neighborhood room\_type                
          MK01         Entire home/apt 1128.00  
                       Private room    1880.00  
                       Shared room       52.00  
          MK02         Entire home/apt  940.00  
                       Private room     141.00  
          {\ldots}                              {\ldots}  
          TS28         Private room     122.00  
          TS29         Entire home/apt  310.00  
                       Private room      83.00  
          TS30         Entire home/apt  851.00  
                       Private room     244.00  
          
          [150 rows x 2 columns]
\end{Verbatim}
            
    \subsection{Lesson 3 - Examine Data - Visualization
(plot)}\label{lesson-3---examine-data---visualization-plot}

    \subsubsection{pandas scatter plot}\label{pandas-scatter-plot}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}146}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}                       
          \PY{c+c1}{\PYZsh{} graph plotting library, conventionally aliased as plt}
          
          \PY{n}{df}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{longitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{latitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                          \PY{n}{colormap} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{jet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{s} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{l+m+mi}{10}\PY{p}{)} 
          \PY{c+c1}{\PYZsh{} and y\PYZhy{}axis uses latitude from df data frame; by default each dot in}
          \PY{c+c1}{\PYZsh{} scatter plot are opaque(i.e. alpha=1.0), to make it more transparent}
          \PY{c+c1}{\PYZsh{} set the alpha to a smaller value; c refers to the color of the dot; }
          \PY{c+c1}{\PYZsh{} s refers to the size of each dot}
                      
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}                                            
          \PY{c+c1}{\PYZsh{} show the generated graph on\PYZhy{}screen    }
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}147}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          
          \PY{n}{df}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{x} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{longitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{latitude}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{c} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{colormap} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{jet}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                          \PY{n}{s} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{where}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{\PYZlt{}} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} if you want to limit the graph to showing listings with prices \PYZgt{} 100,}
          \PY{c+c1}{\PYZsh{} use the np.where function to set the size of the dot to zero (effectively,}
          \PY{c+c1}{\PYZsh{} making it disappear on the graph).}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_23_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Lesson 4 - Data Encoding}\label{lesson-4---data-encoding}

    Most machine learning algorithms work on numeric values only, so there
is a need to encode strings/texual data as numbers. The open source
library, scikit-learn, provides many encoders for data transformations,
including text-to-number encoders, such as LabelEncoder and
OneHotEncoder.

    \subsubsection{scikit-learn
LabelEncoder}\label{scikit-learn-labelencoder}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}148}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelEncoder}
          
          \PY{n}{label\PYZus{}encoder} \PY{o}{=} \PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}                          
          \PY{c+c1}{\PYZsh{} create a new label encoder, which transforms text string list into integer list }
          \PY{n}{label\PYZus{}encoder}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                   
          \PY{c+c1}{\PYZsh{} make the encoder \PYZdq{}learn\PYZdq{} about the data it needs to handle}
          \PY{n}{encoded} \PY{o}{=} \PY{n}{label\PYZus{}encoder}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}   
          \PY{c+c1}{\PYZsh{} encode the data based on what the encoder has \PYZdq{}learnt\PYZdq{}}
\end{Verbatim}


    \subsubsection{scikit-learn
OneHotEncoder}\label{scikit-learn-onehotencoder}

Because the neighborhood feature/column has no inherent
hierarchy/ordering (e.g. neighbouhood MK01 is not necessarily better
than MK02, or MK02 is not better than MK01), we need to further
transform the encoded neighborhood by doing one-hot encoding. One-hot
encoding will transform an integer list into a sparse matrix, where each
colmn corresponds to a unique integral value and each row only has one
column with the integer 1 (all other columns in the row will have the
value zero).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}149}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{OneHotEncoder}
          
          \PY{n}{one\PYZus{}hot\PYZus{}encoder} \PY{o}{=} \PY{n}{OneHotEncoder}\PY{p}{(}\PY{p}{)}                       
          \PY{c+c1}{\PYZsh{} create a new one\PYZhy{}hot encoder}
          \PY{n}{reshaped} \PY{o}{=} \PY{n}{encoded}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}                       
          \PY{c+c1}{\PYZsh{} one\PYZhy{}hot encoder works on list of lists of integer, e.g., [[1],[2]]}
          \PY{c+c1}{\PYZsh{} thus we need to reshape encoded(which is just a list of intergers)}
          \PY{c+c1}{\PYZsh{} as a list of lists of integer}
          
          \PY{n}{one\PYZus{}hot\PYZus{}encoder}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{reshaped}\PY{p}{)}
          \PY{n}{oh\PYZus{}encoded} \PY{o}{=} \PY{n}{one\PYZus{}hot\PYZus{}encoder}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{reshaped}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} oh\PYZus{}encoded is sparse matrix (where most values are zeroes), we need to transform it into a data\PYZhy{}frame }
          \PY{c+c1}{\PYZsh{} so that we can combine this with the original data\PYZhy{}frame}
          
          \PY{n}{smdf} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{oh\PYZus{}encoded}\PY{o}{.}\PY{n}{todense}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PYZbs{}
                              \PY{n}{columns} \PY{o}{=} \PY{n}{label\PYZus{}encoder}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}   
          \PY{c+c1}{\PYZsh{} create a new data\PYZhy{}frame with oh\PYZus{}encoded as the data (rows and}
          \PY{c+c1}{\PYZsh{} columns), and use list captured as classes\PYZus{} (with a trailing}
          \PY{c+c1}{\PYZsh{} underscore) from label\PYZus{}encoder as the column names. Things}
          \PY{c+c1}{\PYZsh{} encoders \PYZdq{}learnt\PYZdq{} are stored in variables with a trailing}
          \PY{c+c1}{\PYZsh{} underscore that we can access and use.}
          
          \PY{n}{d} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf}\PY{p}{)}                                       
          \PY{c+c1}{\PYZsh{} combine the original data\PYZhy{}frame and the newly created smdf}
          \PY{c+c1}{\PYZsh{} data\PYZhy{}frame (side\PYZhy{}by\PYZhy{}side) and store it in variable d; }
          \PY{k}{del} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}                               
          \PY{c+c1}{\PYZsh{} delete the column \PYZsq{}neighborhood\PYZsq{} from d}
\end{Verbatim}


    \subsubsection{scikit-learn
LabelBinarizer}\label{scikit-learn-labelbinarizer}

We can do the label- and one-hot-encoding in one shot with
LabelBinarizer

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}150}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelBinarizer}
          
          \PY{n}{binarizer} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}
          \PY{n}{binarizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{encoded} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{smdf1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{encoded}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
          
          \PY{n}{binarizer} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}
          \PY{n}{binarizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{encoded} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{smdf2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{encoded}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
          \PY{n}{d} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf1}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf2}\PY{p}{)}
\end{Verbatim}


    \subsubsection{running script}\label{running-script}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}151}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelBinarizer}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}                         
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{10}                      
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{width} \PY{o}{=} \PY{l+m+mi}{30}                            
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{k}{lambda} \PY{n}{n} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{n}   
          
          \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}                                    
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tomslee\PYZus{}airbnb\PYZus{}singapore\PYZus{}0116\PYZus{}2015\PYZhy{}06\PYZhy{}28.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  
                  \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}                                 
                  \PY{n}{na\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                               
          
              \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bedrooms}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{host\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reviews}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{overall\PYZus{}satisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accommodates}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{borough}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{minstay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}modified}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}              
              \PY{k}{return} \PY{n}{df}
          
          \PY{k}{def} \PY{n+nf}{encode\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{binarizer} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}
              \PY{n}{binarizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{encoded} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{smdf1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{encoded}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
          
              \PY{n}{binarizer} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}
              \PY{n}{binarizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{encoded} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{smdf2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{encoded}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
              \PY{n}{d} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf1}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf2}\PY{p}{)}
          
          \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{df\PYZus{}encoded} \PY{o}{=} \PY{n}{encode\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\end{Verbatim}


    \subsection{Lesson 5 - Data Scaling}\label{lesson-5---data-scaling}

    Quick tip: scikit-learn has a vary consistent API; you can accomplish a
lot by following the steps below: 1. Create an instance (of whatever you
want to use for processing the data, e.g., LabelBinarizer,
OneHotEncoder, MinMaxScaler) 2. Fit the instance with data: makes it
learn from the data, e.g., calling .fit() on an MinMaxScaler instance
makes it learn the min and max of the features 3. Transform data with
the fit/learned instance: makes the actual transformation on the data

The theory on scaling: As it is common to have different value ranges
for different features, we do not want certain features to have undur
influence on the prediction. While most machine learning algorithms can
deals with different value ranges for different features, it still is
better to scale them to use similar/same value ranges (e.g., 0 to 1)
because it is: 1. Computationally more efficient when calculating the
weights 2. Easier to determine which features are more important by
looking at the weights computed

For example, in linear regression, when the features values are scaled
and the weights for three features are 0.8, 0.1, and 0.3, we can tell
intuitively thta the first feature has a strong positive correlation
with the target value (value of this feature increases together with the
target value).

    \subsubsection{MinMax scaler}\label{minmax-scaler}

MinMax scalers is extremely sensitive to outlier values, but its main
advantage is that you can control the target range you want to scale to.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}152}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{MinMaxScaler}
          
          \PY{n}{scaler} \PY{o}{=} \PY{n}{MinMaxScaler}\PY{p}{(}\PY{p}{)}                            \PY{c+c1}{\PYZsh{} create an instance of the scaler, by default, the scaled range is 0\PYZhy{}1}
          
          \PY{c+c1}{\PYZsh{} assuming df contains only numeric features, i.e., no categorical/textual/string features}
          \PY{n}{df\PYZus{}clean} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PYZbs{}
                             \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{scaler}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df\PYZus{}clean}\PY{p}{)}                               \PY{c+c1}{\PYZsh{} let the scaler \PYZdq{}learn\PYZdq{} from the data what the min and max values are}
          \PY{n}{scaled\PYZus{}df} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}clean}\PY{p}{)}             \PY{c+c1}{\PYZsh{} scale the values to make them \PYZdq{}fit\PYZdq{} inside the range 0 and 1}
\end{Verbatim}


    \subsubsection{Standardization scaler}\label{standardization-scaler}

Standardization scaler is less sensitive to outlier values when there
are enough data, but you can't control the target range. Standardization
scaler works by calculating the average and the standard deviation from
the data, and apply (x - average) / std\_dev for each x in the data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}153}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
          
          \PY{n}{scaler} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}                            
          
          \PY{n}{df\PYZus{}clean} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{scaler}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df\PYZus{}clean}\PY{p}{)}                               
          \PY{n}{scaled\PYZus{}df} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}clean}\PY{p}{)} 
\end{Verbatim}


    It is perfectly okay to use both scalers in the same data-frame for
different features when you deem necessary. Which scaler to use depends
on the data you have.

    \subsection{Lesson 6 - Data
Stratifying}\label{lesson-6---data-stratifying}

    \subsubsection{scikit-learn
train\_test\_split}\label{scikit-learn-trainux5ftestux5fsplit}

train\_test\_split randomly splits the dataset, by default, the
train/test ratio is 3-1 (75\%/25\%).

Sometimes, there are certain ratios we want to maintain because such
ratios influences results, e.g., if the male/female ratio in SG is
40\%/60\%, then any reputable survey should try to maintain as much as
possible that 40\% of the respondents are male and 60\% female. After
all, it is impossible (cost-wise, operationally, etc) to make everyone
in SG to participate in surveys; therefore, surveying a sample size of
the entire population is commonly practiced. Only by maintaining such
ratios would make statements like "40\% of males in SG feel that..."
believable (as long as the sample population is large enough; such
statements are still questionable when there are only 10 participants in
the sample population). Such sampling is called stratified sampling.

\begin{longtable}[c]{@{}llll@{}}
\toprule
... & ... & Male & Female\tabularnewline
\midrule
\endhead
80\% of entire population & Training Data & 40\% & 60\%\tabularnewline
20\% of entire population & Testing Data & 40\% & 60\%\tabularnewline
\bottomrule
\end{longtable}

When such ratios are necessary and when training the machine learning
algorithm from such stratified samples, the trained model can predict
unseen values better becuase it captures the ratio present in the entire
dataset.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}154}]:} \PY{k+kn}{from}  \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          
          \PY{c+c1}{\PYZsh{} split given data into training and testing sets}
          \PY{n}{trainX}\PY{p}{,} \PY{n}{testX} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df}\PY{p}{,}\PYZbs{}
                                           \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PYZbs{}
                                           \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{42}\PY{p}{)}         
          \PY{c+c1}{\PYZsh{} make 20\PYZpc{} of data as testing set}
          \PY{c+c1}{\PYZsh{} set the random number generator with 42 as seed so that }
          \PY{c+c1}{\PYZsh{} every time when this is run with the same data, the result}
          \PY{c+c1}{\PYZsh{} will be the same.}
          
          \PY{n}{trainX}\PY{p}{,} \PY{n}{testX} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PYZbs{}
                                           \PY{n}{stratify}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PYZbs{}
                                           \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PYZbs{}
                                           \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{42}\PY{p}{)}         
          \PY{c+c1}{\PYZsh{} stratified split by room\PYZus{}type}
\end{Verbatim}


    \subsubsection{running script}\label{running-script}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}155}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelBinarizer}
          \PY{k+kn}{from}  \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}                         
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{10}                      
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{width} \PY{o}{=} \PY{l+m+mi}{30}                            
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{k}{lambda} \PY{n}{n} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{n}   
          
          \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}                                    
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tomslee\PYZus{}airbnb\PYZus{}singapore\PYZus{}0116\PYZus{}2015\PYZhy{}06\PYZhy{}28.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  
                  \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}                                 
                  \PY{n}{na\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                                
          
              \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bedrooms}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{host\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reviews}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{overall\PYZus{}satisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accommodates}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{borough}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{minstay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}modified}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}              
              \PY{k}{return} \PY{n}{df}
          
          \PY{k}{def} \PY{n+nf}{encode\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}encode data using LabelBinarizer\PYZsq{}\PYZsq{}\PYZsq{}}
              \PY{n}{binarizer} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}
              \PY{n}{binarizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{encoded} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{smdf1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{encoded}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
          
              \PY{n}{binarizer} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}
              \PY{n}{binarizer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{encoded} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{smdf2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{encoded}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{binarizer}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
              \PY{n}{d} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf1}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{smdf2}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{d}
          
          \PY{k}{def} \PY{n+nf}{stratify\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{trainX}\PY{p}{,} \PY{n}{testX} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PYZbs{}
                                           \PY{n}{stratify}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PYZbs{}
                                           \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PYZbs{}
                                           \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{42}\PY{p}{)}         
              \PY{k}{return} \PY{n}{trainX}\PY{p}{,} \PY{n}{testX}
              
          \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{df\PYZus{}encoded} \PY{o}{=} \PY{n}{encode\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\end{Verbatim}


    \subsection{Lesson 7 - Applying Model for
Prediction}\label{lesson-7---applying-model-for-prediction}

    \subsubsection{rewrite running scripts for
encoding/scaling}\label{rewrite-running-scripts-for-encodingscaling}

As we need to apply the same transformation on training, testing and
production data, the way we previously do encoding/scaling is not
workable: we fit and transformed the transformation based on data we
have (we fed in the entire dataset). For example, our dataset has 3
values for the room\_type feature ("Entire home/apt", "Private room",
"Shared room"), and our previous encoding function encodes them as 0, 1,
2. When we use our previously implemented functions on production data
that somehow contains samples only for "Private room" and "Shared room",
we get 0 as "Private room" and 1 as "Shared room". This is obviously
wrong, as we trained our model with "Private room" as 1 and "Shared
room" as 2! Therefore, we must use the same encoder and scaler (that are
fit on training data) on test and production data too.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}156}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelBinarizer}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
          \PY{k+kn}{from}  \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}                         
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{10}                      
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{width} \PY{o}{=} \PY{l+m+mi}{30}                            
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{k}{lambda} \PY{n}{n} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{n}   
          
          \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}                                    
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tomslee\PYZus{}airbnb\PYZus{}singapore\PYZus{}0116\PYZus{}2015\PYZhy{}06\PYZhy{}28.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  
                  \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}                                 
                  \PY{n}{na\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                                
          
              \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bedrooms}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{host\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reviews}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{overall\PYZus{}satisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accommodates}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{borough}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{minstay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}modified}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}              
              \PY{k}{return} \PY{n}{df}
          
          \PY{k}{def} \PY{n+nf}{stratify\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{train}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PYZbs{}
                                           \PY{n}{stratify}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PYZbs{}
                                           \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PYZbs{}
                                           \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{42}\PY{p}{)}         
              \PY{k}{return} \PY{n}{train}\PY{p}{,} \PY{n}{test}
          
          \PY{k}{def} \PY{n+nf}{create\PYZus{}encoder}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{nlb} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}                               
              \PY{n}{rlb} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}                               
              
              \PY{n}{nlb}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                          
              \PY{n}{rlb}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                             
              
              \PY{k}{def} \PY{n+nf}{inner\PYZus{}encoder}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                  \PY{n}{neighborhood\PYZus{}encoded} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{nlb}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PYZbs{}
                                              \PY{n}{columns} \PY{o}{=} \PY{n}{nlb}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
                  \PY{n}{room\PYZus{}encoded} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{rlb}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PYZbs{}
                                              \PY{n}{columns} \PY{o}{=} \PY{n}{rlb}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
                  \PY{n}{encoded\PYZus{}df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{neighborhood\PYZus{}encoded}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{room\PYZus{}encoded}\PY{p}{)}
                  \PY{k}{return} \PY{n}{encoded\PYZus{}df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{index}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{inner\PYZus{}encoder}
          
          \PY{k}{def} \PY{n+nf}{create\PYZus{}scaler}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{scaler} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}                            
              \PY{n}{scaler}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{)}                               
              
              \PY{k}{def} \PY{n+nf}{inner\PYZus{}scaler}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                  \PY{n}{scaled\PYZus{}df} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{)} 
                  \PY{k}{return} \PY{n}{scaled\PYZus{}df}
              
              \PY{k}{return} \PY{n}{inner\PYZus{}scaler}
              
          \PY{k}{def} \PY{n+nf}{create\PYZus{}transformer}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{encode} \PY{o}{=} \PY{n}{create\PYZus{}encoder}\PY{p}{(}\PY{n}{df}\PY{p}{)}
              \PY{n}{scale} \PY{o}{=} \PY{n}{create\PYZus{}scaler}\PY{p}{(}\PY{n}{encode}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{)}                     
              \PY{c+c1}{\PYZsh{} need to encode given df first before creating the scaler}
          
              \PY{k}{def} \PY{n+nf}{inner\PYZus{}transform}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{n}{scale}\PY{p}{(}\PY{n}{encode}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{inner\PYZus{}transform}
              
          \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{train}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{stratify\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}
              \PY{n}{trainY} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{trainX} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{testY} \PY{o}{=} \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{testX} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
                           
              \PY{n}{transform} \PY{o}{=} \PY{n}{create\PYZus{}transformer}\PY{p}{(}\PY{n}{trainX}\PY{p}{)}              
              \PY{n}{transformed\PYZus{}trainX} \PY{o}{=} \PY{n}{transform}\PY{p}{(}\PY{n}{trainX}\PY{p}{)}
              \PY{n}{transformed\PYZus{}testX} \PY{o}{=} \PY{n}{transform}\PY{p}{(}\PY{n}{testX}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} transformed\PYZus{}prodX = transform(prodX)                  }
              \PY{c+c1}{\PYZsh{} assuming we have the production data in variable prodX}
\end{Verbatim}


    \subsubsection{applying model(linear
model/decisiontree/randomforest)}\label{applying-modellinear-modeldecisiontreerandomforest}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}157}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LinearRegression}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeRegressor}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestRegressor}
          
          \PY{n}{lin\PYZus{}reg} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
          \PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{transformed\PYZus{}trainX}\PY{p}{,} \PY{n}{trainY}\PY{p}{)}
          
          \PY{n}{predictions} \PY{o}{=} \PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{transformed\PYZus{}testX}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} ... training for DecisionTreeRegressor and RandomForestRegressor }
          \PY{c+c1}{\PYZsh{} follows the same steps as above.}
\end{Verbatim}


    Other than manually comparing the predictions against the values in
testY, we can use the following performance measurements to gauge
model's accuracy:

\begin{itemize}
\item
  Root Mean Squared Eoor (RMSE, also known as Euclidian distance, or L2
  norm): essentially, \[\sqrt{\frac{\Sigma(p-a)^2}{n}}\] where p =
  prediction, a = actual value, n = number of predictions/actual values.
\item
  Mean Absolute Error (MAE, also known as Manhattan distance, or L1
  norm): essentially, \[\frac{\Sigma(|p - a|)}{n}\]
\end{itemize}

The lower the scores, the better/more accurate the model; however, if
the score is closed to zero, that most likely means the model has
overfit the data. Note that RMSE and MAE are cost functions (lower is
better). There are measurement functions known as utility functions
(higher is better), such distinction is important with you do
cross-valuation.

    \subsubsection{running script}\label{running-script}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}158}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{LabelBinarizer}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
          \PY{k+kn}{from}  \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LinearRegression}
          
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{10}                        
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}columns} \PY{o}{=} \PY{l+m+mi}{10}                      
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{width} \PY{o}{=} \PY{l+m+mi}{30}                            
          \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{float\PYZus{}format} \PY{o}{=} \PY{k}{lambda} \PY{n}{n} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.2f}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}}\PY{k}{n}   
          
          \PY{k}{def} \PY{n+nf}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}                                    
                  \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tomslee\PYZus{}airbnb\PYZus{}singapore\PYZus{}0116\PYZus{}2015\PYZhy{}06\PYZhy{}28.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}  
                  \PY{n}{delimiter} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}                                 
                  \PY{n}{na\PYZus{}values} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{?}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                               
          
              \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bedrooms}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{host\PYZus{}id}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{reviews}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{overall\PYZus{}satisfaction}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accommodates}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{borough}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{minstay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PYZbs{}
                            \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}modified}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}              
              \PY{k}{return} \PY{n}{df}
          
          \PY{k}{def} \PY{n+nf}{stratify\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{train}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PYZbs{}
                                           \PY{n}{stratify}\PY{o}{=}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PYZbs{}
                                           \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}\PYZbs{}
                                           \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{42}\PY{p}{)}         
              \PY{k}{return} \PY{n}{train}\PY{p}{,} \PY{n}{test}
          
          \PY{k}{def} \PY{n+nf}{create\PYZus{}encoder}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{nlb} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}                               
              \PY{n}{rlb} \PY{o}{=} \PY{n}{LabelBinarizer}\PY{p}{(}\PY{p}{)}                               
              
              \PY{n}{nlb}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                          
              \PY{n}{rlb}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}                             
              
              \PY{k}{def} \PY{n+nf}{inner\PYZus{}encoder}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                  \PY{n}{neighborhood\PYZus{}encoded} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{nlb}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PYZbs{}
                                              \PY{n}{columns} \PY{o}{=} \PY{n}{nlb}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
                  \PY{n}{room\PYZus{}encoded} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{rlb}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PYZbs{}
                                              \PY{n}{columns} \PY{o}{=} \PY{n}{rlb}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
                  \PY{n}{encoded\PYZus{}df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{neighborhood\PYZus{}encoded}\PY{p}{)}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{room\PYZus{}encoded}\PY{p}{)}
                  \PY{k}{return} \PY{n}{encoded\PYZus{}df}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neighborhood}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{index}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{inner\PYZus{}encoder}
          
          \PY{k}{def} \PY{n+nf}{create\PYZus{}scaler}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{scaler} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}                            
              \PY{n}{scaler}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df}\PY{p}{)}                               
              
              \PY{k}{def} \PY{n+nf}{inner\PYZus{}scaler}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                  \PY{n}{scaled\PYZus{}df} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df}\PY{p}{)} 
                  \PY{k}{return} \PY{n}{scaled\PYZus{}df}
              
              \PY{k}{return} \PY{n}{inner\PYZus{}scaler}
              
          \PY{k}{def} \PY{n+nf}{create\PYZus{}transformer}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
              \PY{n}{encode} \PY{o}{=} \PY{n}{create\PYZus{}encoder}\PY{p}{(}\PY{n}{df}\PY{p}{)}
              \PY{n}{scale} \PY{o}{=} \PY{n}{create\PYZus{}scaler}\PY{p}{(}\PY{n}{encode}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{)}                     
          
              \PY{k}{def} \PY{n+nf}{inner\PYZus{}transform}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{n}{scale}\PY{p}{(}\PY{n}{encode}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{inner\PYZus{}transform}
              
          \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
              \PY{n}{df} \PY{o}{=} \PY{n}{load\PYZus{}data}\PY{p}{(}\PY{p}{)}
              \PY{n}{train}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{stratify\PYZus{}data}\PY{p}{(}\PY{n}{df}\PY{p}{)}
              \PY{n}{trainY} \PY{o}{=} \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{trainX} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{testY} \PY{o}{=} \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{testX} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
                           
              \PY{n}{transform} \PY{o}{=} \PY{n}{create\PYZus{}transformer}\PY{p}{(}\PY{n}{trainX}\PY{p}{)}              
              \PY{n}{transformed\PYZus{}trainX} \PY{o}{=} \PY{n}{transform}\PY{p}{(}\PY{n}{trainX}\PY{p}{)}
              \PY{n}{transformed\PYZus{}testX} \PY{o}{=} \PY{n}{transform}\PY{p}{(}\PY{n}{testX}\PY{p}{)}
              \PY{c+c1}{\PYZsh{} transformed\PYZus{}prodX = transform(prodX)                  }
              
              \PY{n}{lin\PYZus{}reg} \PY{o}{=} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}
              \PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{transformed\PYZus{}trainX}\PY{p}{,} \PY{n}{trainY}\PY{p}{)}
              \PY{n}{predictions} \PY{o}{=} \PY{n}{lin\PYZus{}reg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{transformed\PYZus{}testX}\PY{p}{)}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
